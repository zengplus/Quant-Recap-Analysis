# **实验日记 (Experiment Log) - V0.1**

> **日期**: 2026-02-05  
> **版本**: V0.1  
> **主题**: **回测体系重构与线上线下对齐的发现与解决**  
> **状态**: 完成

## **1. 核心发现**

### **1.1 问题的发现：收益差异与分数不一致**
在前期研究中，模型在2025周期展现出高达**50%**的回测收益。然而，当将该策略部署到聚宽线上平台进行回测时，只能获得约**15-17%**的收益，两者存在显著差距。

**排查第一层：数据源差异？**
最初怀疑是数据差异导致的。聚宽平台使用分钟级数据进行回测，而本地使用日线数据：
- 分钟级回测：能更精细地模拟交易，考虑盘中价格变化和流动性
- 日线回测：假设以收盘价成交，可能高估可成交性

**处理措施**：为对齐线上环境，我在本地回测中添加了以下限制：
1. **涨停板限制**：当股票当日开盘价到收盘价涨幅≥9.7%时，视为涨停无法买入
2. **换手率过滤**：剔除当日换手率极低的股票（流动性不足）
3. **市场限制**：剔除了科创板、北交所等波动率较大的股票，只保留主板和创业板

**结果**：尽管这些措施缩小了部分差距，但本地回测仍显著高于线上结果，说明**这不是核心原因**。

### **1.2 问题的定位：归一化中的未来函数**
通过逐层排查，最终发现问题根源在于**因子归一化的时间窗口不一致**。

**关键排查过程**：
1. **分数对比**：在本地和线上同步计算相同股票池、相同时间点的因子得分
2. **发现差异**：即使输入数据完全相同，计算出的因子分数仍存在系统性偏差
3. **深入分析**：发现 `robust_norm` 函数在计算中位数时使用了**全局统计量**而非**滚动统计量**

**问题本质**：
- **本地计算（错误）**：`torch.nanmedian(t, dim=1)` 一次性计算了整个时间序列（2023-2025）的中位数
- **线上计算（正确）**：聚宽平台在每日回测时，只能使用**当日及以前**的数据进行归一化

### **1.3 验证实验：真伪策略对比**
为了量化这种差异，我设计了验证脚本 `verify_real_performance.py`：

**实验设置**：
- 时间区间：2025年全年的股票数据
- 对比方法：全局归一化 vs. 滚动归一化
- 评估指标：RankIC（因子与下期收益的秩相关系数）

**实验结果**：
- **Case 1 (全局归一化)**：RankIC = **-0.0540**（负相关，策略失效）
- **Case 2 (滚动归一化)**：RankIC = **+0.0664**（正相关，策略有效）

**结论**：
- 研究幻觉：全局归一化在某些时期（如2023-2024）创造了虚假的高收益（50%）
- 真实能力：滚动归一化下策略展现的真实选股能力，对应线上平台的15-17%收益
- 反直觉发现：在某些市场阶段（如2025年），使用未来信息反而会**损害**策略表现

### **1.4 新问题：公式修复**
在完成基础验证后，我发现即使解决了归一化问题，线上/线下的收益仍存在差异。为了进一步排查，我进行了逐月持仓对比分析，发现了更深层次的差异源：

**问题根源**：公式Token序列的可执行性问题
- 训练输出：模型生成的是原始Token序列，可能不符合后缀表达式语法约束
- 线上修复：聚宽平台在初始化时会进行解析修复（如补充缺失参数、调整栈深度）
- 本地缺失：初期本地回测直接使用原始Token，导致实际执行的"公式"并非设计意图

**关键发现**：
- 训练阶段输出的是token序列，但token序列并不总是一个合法可执行的后缀表达式（栈深/算子元数可能不满足约束）
- 如果直接用raw token执行，VM可能会走"缺参补默认值"等兜底路径，导致实际计算信号与日志打印的表达式不一致
- 因此最终回测应当以 **repair_postfix后得到的合法token** 为准。该token才能被一致地解码、执行、复现

**最终确认**：通过将本地回测改为使用修复后的Token序列，持仓差异大幅减少，验证了这是影响收益一致性的重要因素。

### **1.5 深层次问题：同分并列现象**
在解决了公式修复问题后，我开始进行月度持仓对比，发现了另一个隐藏问题：

**极端案例：大规模同分现象**
在逐月对比持仓时，发现某些月份存在惊人的现象：
- **极端公式特征**：部分训练效果较差的公式会输出常数因子，如全体股票得分均为1
- **大规模同分**：这种情况下，前1名到前200多名股票完全同分，都得到相同的得分1
- **选择随机化**：TopK选择在这种场景下完全退化为按股票池顺序选择

**临界情况：小规模并列**
除了极端情况外，更常见的是边界处的同分现象：
- **临界点同分**：如第10、11、12名股票得分完全相同
- **微调效应**：即使只有少数股票同分，也可能导致仓位持有1-2个股票的差异
- **累积效应**：这些微小的持仓差异逐月累积，最终造成显著的收益偏差

**待解决问题**：
目前尚未找到完全解决同分并列问题的方法，只能通过以下方式缓解：
- 在公式生成阶段避免产生常数因子
- 在同分情况下采用一致的二级排序规则
- 监测并记录同分情况的影响程度

## **2. 关键改动：构建真实的回测体系**

### **2.1 数据流重构**
1. **滚动归一化实现**：
   - 将所有特征计算的归一化窗口改为**120日滚动窗口**
   - 确保每个时间点的统计量仅基于历史数据计算

2. **内存优化**：
   - 使用730天初始化缓冲区计算长期指标
   - 计算完成后立即进行物理切片：`tensor[..., 730:]`
   - 释放初始缓冲区内存，模拟线上环境约束

3. **计算图优化**：
   - 在`evaluate_formula`函数添加`@torch.no_grad()`装饰器
   - 切断推理阶段的计算图，显存占用下降约90%

### **2.2 回测体系强化**
1. **交易规则对齐**：
   - 佣金：万三
   - 印花税：千一（卖出时收取）
   - 严格执行T+1交易制度

2. **价格序列处理**：
   - 因子计算：使用**前复权价格**，保证计算连续性
   - 交易撮合：使用**不复权价格**，与实际交易一致

3. **流动性模拟改进**：
   - 保留涨停板买入失败机制
   - 但对科创板、北交所股票进行单独评估，不过滤而是差异化处理

### **2.3 模型训练优化**
1. **Reward设计**：
   - 保持截面标准化（Cross-Sectional Normalization）
   - 使用Sortino比率作为风险调整收益指标

2. **正则化加强**：
   - LoRD（Low-Rank Decay）正则化，防止过拟合噪声
   - Looped Transformer层，增加深度而不显著增加参数量

### **2.4 线上回测一致性加固**
为进一步减少"同一公式两边跑出来不一样"的情况，新增了以下对齐与诊断机制：

1. **统一"先修复、再执行"的公式口径**：
   - 线上（JoinQuant）在初始化时记录 `tokens(raw)` / `tokens(repaired)` 与公式来源，回测期间以修复后的token作为最终执行依据
   - 本地在生成信号矩阵时同样先对token做repair，再执行VM，避免raw token走兜底补参导致的口径漂移

2. **加强公式可追溯性**：
   - 线上日志额外打印：公式来源、token_mode、tokens(raw)、tokens(repaired)，便于和本地逐日逐股对齐

3. **统一调仓日与信号滞后口径**：
   - 调仓：每月第一个交易日开盘
   - 信号使用：在 `signal_lag=1` 时，用调仓日前一交易日的分数做排名（避免未来函数）

4. **为"同分并列"引入诊断日志**：
   - 若TopK的截断点落在并列分数区间内，线上会输出告警，明确提示"入选会受股票池顺序影响"并给出并列覆盖的名次范围
   - 若并列仅发生在TopK内部且不影响入选，仅提示"影响TopK内部顺序"

## **3. 结果分析**

### **3.1 实验设置**
- **数据范围**：2018-2025年
- **训练/验证/测试**：2018-2023/2024/2025
- **基准对比**：CSI300指数
- **实验次数**：5次独立随机种子实验

### **3.2 性能对比**

**基准表现**：
- CSI300 2024年收益：+14.68%
- CSI300 2025年收益：+17.66%

| Run ID | 训练集收益   | 验证集收益   | 测试集收益   | 测试集IR | 超额收益    |
| ------ | ------- | ------- | ------- | ----- | ------- |
| Run 01 | -48.91% | +8.66%  | +13.74% | -0.40 | -3.92%  |
| Run 02 | -37.18% | +14.09% | -7.25%  | -0.71 | -24.91% |
| Run 03 | -55.62% | +10.01% | -13.93% | -1.42 | -31.59% |
| Run 04 | -59.32% | -0.55%  | -10.72% | -1.99 | -28.38% |
| Run 05 | -57.84% | +13.57% | +8.51%  | -0.59 | -9.15%  |

### **3.3 核心发现**

1. **真实性验证通过**：
   - 测试集收益范围（-13.93% ~ +13.74%）与聚宽平台结果（15-17%）**数量级一致**
   - 彻底消除了"50%收益幻觉"，建立了可信的基线

2. **新问题暴露**：
   - **训练失败**：所有种子在训练集上均为深度负收益
   - **超额收益为负**：即使获得正绝对收益（Run01/05），仍跑输基准
   - **高波动性**：IR均为负值，策略不稳定
   - **种子敏感性高**：不同种子结果差异巨大

## **4. 问题诊断**

### **4.1 诊断：为什么训练会失败？**

**问题根源**：当前Reward函数设计存在逻辑缺陷。

**具体分析**：
1. **Sortino比率的陷阱**：在探索阶段，随机生成的因子会产生巨大的下行波动
2. **负向强化**：模型"发现"产生极端负收益但波动较小的信号，可以获得相对"较好"的Sortino值
3. **局部最优陷阱**：模型陷入"稳定亏损"的局部最优解

### **4.2 诊断：正收益为什么跑输基准？**

**原因分析**：
1. **Beta暴露错误**：策略可能错误地暴露在市场风险下
2. **策略不一致**：高波动导致长期期望收益为负
3. **训练目标偏差**：Reward函数未明确鼓励超额收益

### **4.3 诊断：种子间差异为何如此巨大？**

**原因分析**：
1. **RL算法的固有问题**：REINFORCE算法的高方差特性
2. **金融数据的噪音**：信噪比极低，不同种子学习到不同噪声模式
3. **优化地形复杂**：存在多个局部最优解

### **Q1: 为什么项目重点使用截面数据(Cross-Sectional)而非纯时序数据(Time-Series)？**

**A:**
这是一个关于**Alpha本质**的问题。我们必须区分**特征工程**与**因子评估**两个阶段：

1.  **特征输入阶段**：我们确实使用了**时序处理**（如120天滚动归一化），这是为了保证数据的平稳性，并严格消除未来函数（不能用明天的均值来标准化今天的数据）
2.  **因子评估与Reward阶段**：我们必须使用**截面数据**（Cross-Sectional Ranking）
    - **选股 vs 择时**：Alpha策略的核心是**选股**，即"在同一时刻，找出比其他股票更好的股票"。这是一个横向对比（截面）的过程
    - **消除 Beta**：通过截面标准化（如Rank或Z-Score），我们去掉了大盘整体涨跌（Beta）的影响。即使大盘暴跌，只要我们选的股票跌幅小于平均水平，截面收益就是正的。这符合量化对冲（Market Neutral）的初衷

### **Q2: 在这个内存限额问题上你是怎么解决的？**

**A:**
在处理大规模金融数据（如A股全市场日线数据）时，显存是最大的瓶颈。我采取了**物理切片**与**计算图剪枝**相结合的策略：

1.  **物理切片 (Physical Slicing)**：
    - **背景**：为了计算120天均线，Dataloader必须预加载730天的Buffer数据。如果把这些Buffer放入GPU，会浪费大量显存
    - **方案**：编写了`slice_loader`函数。在CPU端完成滚动特征计算后，**物理删除**前730天的数据，只把有效的训练数据传入GPU。这使得显存利用率提高了30%以上
2.  **计算图剪枝 (Graph Pruning)**：
    - **背景**：在强化学习的Rollout阶段（生成公式 -> 计算因子值），我们需要计算因子值来得到Reward，但这步计算不需要反向传播
    - **方案**：在`evaluate_formula`函数上添加`@torch.no_grad()`装饰器，强制切断PyTorch的计算图构建。这不仅减少了90%的临时显存占用，还大幅提升了推理速度

### **Q3: 对于这个模型你是怎么处理的？（模型架构决策）**

**A:**
针对金融数据**高噪音、低信噪比**的特点，我没有直接套用标准的NLP模型，而是做了特定的魔改：

1.  **Looped Transformer (权重共享)**：
    - **原理**：让Transformer的同一层权重循环使用多次（如Loop 3次）
    - **目的**：模拟人类"反复思考"的过程，增加了模型的推理深度（Depth），但参数量（Parameters）保持不变。这极大地降低了过拟合的风险，适合金融这种"数据虽多但有效信号很少"的场景
2.  **LoRD 正则化 (Low-Rank Decay)**：
    - **原理**：强制Attention矩阵保持低秩（Low Rank）
    - **目的**：金融市场中，大部分波动是随机噪音，只有少部分是核心逻辑（低秩结构）。LoRD强迫模型忽略噪音，只捕捉最强的主成分信号

## **5. 改进计划**

### **5.1 首要任务：修复训练失败问题**

**Reward函数重构方案**：model_core/ashare_backtest.py

当前公式逻辑：
```
down_std = sqrt(...) + 1e-9 （分母加了一个极小值）
score = sortino * 2.0 + cum_ret * 10.0 （Sortino权重为2，累计收益权重为10）
```

| 方案 | 核心思想 | 优势 & 优点 | 适用阶段 |
|------|----------|-------------|----------|
| **方案 A**<br>(IC驱动) | **IC（信息系数）**作为主要奖励 | **数值稳定**（[-1, 1]）；直接衡量因子预测能力 | **初期**<br>（引导方向） |
| **方案 B**<br>(对数收益) | 使用`log(1+ret)`代替原始收益 | **压缩尺度**；对称处理盈亏，防止大亏损破坏训练 | **中后期**<br>（平衡风险） |
| **方案 C**<br>(平滑Sortino) | 分母加入`base_vol`：<br>`sqrt(var + base_vol^2)` | **防止爆炸**；Sortino值稳定在[-2, 2] | **全阶段**<br>（稳定信号） |

### **5.2 辅助改进措施**

1. **算法稳定性提升**：
   - 考虑PPO等更稳定的RL算法
   - 增加熵正则项，鼓励探索

2. **训练策略优化**：
   - 实现课程学习：从简单时期（平稳市场）开始训练
   - 逐步增加数据复杂度和时间范围

3. **监控体系完善**：
   - 实时监控训练过程中的Beta暴露
   - 定期计算IC、换手率等关键指标

### **5.3 V0.2成功标准**

1. **基本要求**：
   - 训练集收益 > 0%（证明模型能学会赚钱）
   - 测试集至少3/5种子获得正超额收益

2. **进阶目标**：
   - 测试集平均IR > 0
   - 策略换手率控制在合理范围（< 100%月频）

3. **长期愿景**：
   - 建立稳定、可复现的Alpha生成框架
   - 实现策略逻辑的可解释性分析

### **5.4 同分并列问题的长期解决方案**

虽然同分并列问题在当前阶段没有完美的解决方案，但我们可以在后续工作中探索以下方向：

1. **因子设计优化**：
   - 在公式生成阶段加入约束，避免产生常数因子
   - 引入因子多样性惩罚项，鼓励模型生成有区分度的因子

---

**实验小结**：
通过本次实验，我们成功定位并解决了导致线上/线下收益差异的三大核心问题：
1. **归一化未来函数**：使用滚动窗口替代全局统计，消除未来信息泄露
2. **公式修复不一致**：统一使用修复后的Token序列，确保公式执行的一致性
3. **同分并列处理**：建立同分检测和告警机制，减少随机性影响

这一过程不仅修正了技术实现，更重要的是**构建了真实可信的回测体系**，为后续模型优化奠定了坚实基础。虽然同分并列问题尚未完全解决，但我们已经建立了监控和诊断机制，并规划了长期解决方案的方向。